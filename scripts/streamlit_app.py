import os
import re
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from matplotlib import font_manager, rc
import requests

def get_file_path(local_path: str, cloud_path: str) -> str:
    #ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    if os.path.exists(local_path):
        return local_path
    elif os.path.exists(cloud_path):
        return cloud_path
    else:
        raise FileNotFoundError(f"Neither '{local_path}' nor '{cloud_path}' exists.")

# ì´ë¯¸ì§€ ê²½ë¡œ ë°°ì—´
image_files = [
    ("images/ê°œìš”.png", "scripts/images/ê°œìš”.png"),
    ("images/ì›Œí¬í”Œë¡œìš°.png", "scripts/images/ì›Œí¬í”Œë¡œìš°.png"),
    ("../results/figures", "results/figures"),
    ("../results/figures/negative_data_ratio.png", "results/figures/negative_data_ratio.png"),
    ("../results/figures/negative_columns_top2.png", "results/figures/negative_columns_top2.png"),
    ("../results/figures/negative_columns_rest.png", "results/figures/negative_columns_rest.png"),
    ("../results/figures/corr.png", "results/figures/corr.png"),
    ("../results/figures/corr_network.png", "results/figures/corr_network.png"),
    ("../results/figures/col_drop.png", "results/figures/col_drop.png"),
    ("../results/reports/models_scores.csv", "results/reports/models_scores.csv"),
    ("../results/reports/xgb_scaler_None_pca_None_report.txt", "results/reports/xgb_scaler_None_pca_None_report.txt")
]

# í•œê¸€ í°íŠ¸ ê²½ë¡œ ì„¤ì •
# font_path = os.path.join(os.getcwd(), get_file_path("fonts", "scripts/fonts"), "BATANG.TTC")
# font_name = font_manager.FontProperties(fname=font_path).get_name()
# rc('font', family=font_name)

def download_font(url, save_path):
    if not os.path.exists(save_path):
        print(f"Downloading font from {url}...")
        response = requests.get(url)
        with open(save_path, "wb") as f:
            f.write(response.content)
        print(f"Font downloaded to {save_path}")
        
# í°íŠ¸ ë‹¤ìš´ë¡œë“œ
font_url = "https://github.com/JiAhLee903/Intrusense/tree/main/scripts/fonts/BATANG.TTC"  # í°íŠ¸ íŒŒì¼ URL
font_path = os.path.join(get_file_path("fonts", "scripts/fonts"), "BATANG.TTC")
download_font(font_url, font_path)
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# ë©”ì¸ í˜ì´ì§€
st.title("Intrusense")

pages = st.tabs(["ğŸ ë©”ì¸ í˜ì´ì§€", "ğŸ”ë°ì´í„° ë¶„ì„ ë° íƒìƒ‰", "ğŸ“Šëª¨ë¸", "ğŸ“„ë³´ê³ ì„œ"])

# ë©”ì¸ í˜ì´ì§€
with pages[0]:
    # íŒ€ëª… ì˜ë¯¸
    st.markdown("<h4>íŒ€ëª… ì˜ë¯¸</h4>", unsafe_allow_html=True)
    st.markdown("""Intrusense**ëŠ” Intrusion(ì¹¨ì…)+Sense(ê°ê°)ì˜ í•©ì„±ì–´ë¡œ, ì‚¬ì´ë²„ ì¹¨ì…ì„ ê°ì§€**í•˜ê² ë‹¤ëŠ” ì˜ë¯¸""")

    # íŒ€ì› ì†Œê°œ
    st.markdown("<h4>íŒ€ì› ì†Œê°œ</h4>", unsafe_allow_html=True)
    team_members = [
        {"name": "ì´ì§€ì•„", "role": "PM", "description": "í”„ë¡œì íŠ¸ ì´ê´„ ë° ê´€ë¦¬"},
        {"name": "ì†ìœ¤ê¸°", "role": "ML ì—”ì§€ë‹ˆì–´", "description": "ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œê°í™”"},
        {"name": "ì¡°í˜„", "role": "ML ì—”ì§€ë‹ˆì–´", "description": "ëª¨ë¸ ë¶„ì„ ë° í”„ë ˆì„ì›Œí¬ ê°œë°œ"},
        {"name": "ë¬¸ê²½ì€", "role": "ML ì—”ì§€ë‹ˆì–´", "description": "ë°ì´í„° ì „ì²˜ë¦¬ ì§€ì› ë° ë¶„ì„"}
    ]

    # íŒ€ì› ì •ë³´ë¥¼ ì—´ë¡œ ì •ë¦¬
    cols = st.columns(len(team_members))  
    for col, member in zip(cols, team_members):
        with col:
            st.markdown(f"**{member['name']}**")
            st.markdown(f"*{member['role']}*")
            st.write(member['description'])

    # ì„œë¸Œíƒ­ ì„¤ì •
    tabs = st.tabs(["í”„ë¡œì íŠ¸ ê°œìš”", "ë°ì´í„°ì…‹ ìš”ì•½", "ì „ì²´ ì›Œí¬í”Œë¡œ ë‹¤ì´ì–´ê·¸ë¨"])

    # í”„ë¡œì íŠ¸ ê°œìš” íƒ­
    with tabs[0]:
        st.markdown("<h4>í”„ë¡œì íŠ¸ ê°œìš”</h4>", unsafe_allow_html=True)
        st.markdown('ì‚¬ì´ë²„ ë³´ì•ˆ ìœ„í˜‘ì´ ì ì  ë” ë³µì¡í•˜ê³  ì •êµí•´ì§ì— ë”°ë¼, íš¨ìœ¨ì ì´ê³  ì‹ ë¢°ì„± ìˆëŠ” ì¹¨ì… íƒì§€ ì‹œìŠ¤í…œì˜ í•„ìš”ì„±ì´ ê°•ì¡°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì— ìš°ë¦¬ íŒ€ì€ ë‹¤ì–‘í•œ ì‚¬ì´ë²„ ê³µê²© ìœ í˜•ì„ í¬í•¨í•œ í˜„ì‹¤ì ì¸ ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬, ì‹¤ì œ í™˜ê²½ì—ì„œë„ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ ì¹¨ì… íƒì§€ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³ ì í•©ë‹ˆë‹¤.')
        st.markdown("<h5>- ì „í†µì  íƒì§€ê¸°ë²•ë§ê³  aië¥¼ ì™œ í™œìš©í•´ì•¼í• ê¹Œ?</h5>", unsafe_allow_html=True)
        st.info("ğŸ’¡ì‹¤ì œ ai ê¸°ë°˜ ë³´ì•ˆ ì‚°ì—…ì— **ì •í™•ë„**ì™€ **ìœ ì—°ì„±**ì„ ë°”íƒ•ìœ¼ë¡œí•˜ëŠ” **AI ê¸°ë°˜ ì†”ë£¨ì…˜**ì˜ ì±„íƒë¥  ì¦ê°€í•˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤.")
        # ì´ë¯¸ì§€ ì‚½ì…
        local, cloud = image_files[0]
        st.image(get_file_path(local, cloud), caption="AI ë³´ì•ˆ ì‹œì¥ ì¶œì²˜: ì •ë³´í†µì‹ ì‹ ë¬¸ (https://www.koit.co.kr/news/articleView.html?idxno=126833)", use_container_width=True)
        st.markdown("<h4>ëª©ì  ë° ëª©í‘œ</h4>", unsafe_allow_html=True)
        st.info("âœ”ï¸ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ê¸°ë°˜ ì¹¨ì… íƒì§€ ëª¨ë¸ì„ ë§Œë“¤ê¸°")
        st.info("âœ”ï¸ ì •í™•ë„ 99% ì´ìƒì— ëª¨ë¸ì„ ë§Œë“¤ê¸°")

    # ë°ì´í„°ì…‹ ìš”ì•½ íƒ­
    with tabs[1]:
        
        st.markdown("<h4>ë°ì´í„°ì…‹</h4>", unsafe_allow_html=True)
        st.markdown("""<span style="background-color: grey; text-decoration: underline; font-weight: bold;">CIC-IDS 2017</span> : Canadian Institute for Cybersecurityì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹
                      \n- **ë°ì´í„° ì €ì¥ ë°©ì‹**: MySQL ë°ì´í„°ë² ì´ìŠ¤
          \n- **ë°ì´í„° ê·œëª¨**: 78ê°œì˜ í”¼ì²˜, 1ê°œì˜ íƒ€ê²Ÿ ë ˆì´ë¸”, ì´ 225,745ê°œì˜ í–‰(Row)""", unsafe_allow_html=True)
       
        # st.markdown("<h4>ë°ì´í„° ì„¤ëª… ë° ì°¨ìš© ì´ìœ </h4>", unsafe_allow_html=True)
        # st.write("CIC(Canadian Institute for Cybersecurity)ì€ ì‚¬ì´ë²„ ê³µê²© ìœ í˜•ì„ í¬í•¨í•œ ë°ì´í„°ì…‹ì„ ì œê³µí•˜ì—¬ ë³´ì•ˆ ì—°êµ¬ì™€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œì— í™œìš©ë˜ê¸°ë–„ë¬¸ì— ë°ì´í„°ì— ì‹ ë¢°ë„ê°€ ë†’ìŠµë‹ˆë‹¤.")
        # st.write("í˜„ì‹¤ì ì¸ ë°ì´í„° êµ¬ì¡° CIC ë°ì´í„°ì…‹ì€ í˜„ì‹¤ì ì¸ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì—ì„œ ìƒì„±ëœ ë°ì´í„°ì´ê¸° ë•Œë¬¸ì—, í•™ìŠµ ëª¨ë¸ì´ ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì—ì„œë„ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.")
        # st.write('ë‹¨ì¼ ìœ í˜•ì˜ ê³µê²©ë§Œ í¬í•¨ëœ ë°ì´í„°ì…‹ê³¼ëŠ” ë‹¬ë¦¬, CIC ë°ì´í„°ì…‹ì€ ì—¬ëŸ¬ ê³µê²© ìœ í˜•ì„ í¬í•¨í•˜ê³  ìˆì–´ ë‹¤ì–‘í•œ ì—°êµ¬ì™€ ì‹¤í—˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.')
        
    #     st.markdown("""
    #     #### **í”¼ì²˜ ì¢…ë¥˜**
    #     - **í¬íŠ¸ ë° íŠ¸ë˜í”½ëŸ‰**
    #     - **íŒ¨í‚· ê¸¸ì´**
    #     - **í”Œë˜ê·¸ ë° í—¤ë”**
    #     - **ì†ë„ ë° ë¹„ìœ¨**
    #     - **ì„¸ê·¸ë¨¼íŠ¸ ë° í•˜ìœ„ í”Œë¡œìš°**
    # """)
        
        import pandas as pd

        # ëŒ€í‘œ ê³µê²© ë°ì´í„°
        attacks_data = {
            "ê³µê²© ìœ í˜•": [
                "DDoS", 
                "PortScan", 
                "Bot", 
                "Web Attack SQL Injection", 
                "Heartbleed"
            ],
            "ì„¤ëª…": [
                "ë¶„ì‚° ì„œë¹„ìŠ¤ ê±°ë¶€ ê³µê²©.", 
                "ë„¤íŠ¸ì›Œí¬ í¬íŠ¸ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì·¨ì•½ì ì„ íƒìƒ‰í•˜ëŠ” ê³µê²©.", 
                "ì•…ì„± ë´‡ì— ê°ì—¼ëœ ì¥ì¹˜ì˜ ë„¤íŠ¸ì›Œí¬ í™œë™.", 
                "SQL ë¬¸ë²•ì„ ì•…ìš©í•œ ë°ì´í„°ë² ì´ìŠ¤ ê³µê²©.", 
                "OpenSSL ì·¨ì•½ì ì„ ì•…ìš©í•´ ë¯¼ê° ì •ë³´ë¥¼ ìœ ì¶œí•˜ëŠ” ê³µê²©."
            ]
        }

        # ì£¼ìš” ì¹¼ëŸ¼ ë°ì´í„°
        columns_data = {
            "ì¹¼ëŸ¼ëª…": [
                "Flow Duration", 
                "Total Fwd Packets, Total Backward Packets", 
                "Flow Bytes/s, Flow Packets/s", 
                "Flow IAT Mean, Flow IAT Std", 
                "Fwd Packet Length Max, Fwd Packet Length Mean", 
                "Bwd Packet Length Max, Bwd Packet Length Mean", 
                "PSH Flags Count, URG Flags Count", 
                "SYN Flag Count, FIN Flag Count, RST Flag Count", 
                "Label"
            ],
            "ì„¤ëª…": [
                "íë¦„ì˜ ì§€ì† ì‹œê°„. ê³µê²©ê³¼ ì •ìƒ íŠ¸ë˜í”½ì˜ ì°¨ì´ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ì¤‘ìš”í•œ ì§€í‘œ.",
                "ì „ì†¡ ë° ìˆ˜ì‹ ëœ ì´ íŒ¨í‚· ìˆ˜. ì˜ˆ) DDoS ê³µê²© ì‹œ íŒ¨í‚· ìˆ˜ ê¸‰ì¦.",
                "ì´ˆë‹¹ ë°”ì´íŠ¸ ë° íŒ¨í‚· ìˆ˜. ì´ìƒ íŠ¸ë˜í”½ì—ì„œ ê°’ì´ ê¸‰ê²©íˆ ë³€í•  ê°€ëŠ¥ì„±ì´ í¼.",
                "íŠ¸ë˜í”½ì˜ ì‹œê°„ ê°„ê²©. ê³µê²© ì‹œ ê°„ê²©ì˜ ì¼ì •ì¹˜ ì•ŠìŒì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŒ.",
                "ìˆœë°©í–¥ íŒ¨í‚·ì˜ ìµœëŒ€ ë° í‰ê·  ê¸¸ì´.",
                "ì—­ë°©í–¥ íŒ¨í‚·ì˜ ìµœëŒ€ ë° í‰ê·  ê¸¸ì´.",
                "í‘¸ì‹œ(PSH)ì™€ ê¸´ê¸‰(URG) í”Œë˜ê·¸ê°€ ì„¤ì •ëœ íŒ¨í‚· ìˆ˜.",
                "ì—°ê²° ìš”ì²­ ë° ì¢…ë£Œ ê´€ë ¨ í”Œë˜ê·¸. ê³µê²© íƒì§€ì— í™œìš© ê°€ëŠ¥.",
                "ê° íŠ¸ë˜í”½ì˜ ë ˆì´ë¸”(ì •ìƒ/ê³µê²© ìœ í˜•)."
            ]
        }

        # íƒ€ê²Ÿ ë ˆì´ë¸” ë°ì´í„°
        target_labels_data = {
            "íƒ€ê²Ÿ ë ˆì´ë¸”": [
                "BENIGN", 
                "DDoS", 
                "PortScan", 
                "Bot", 
                "Infiltration", 
                "Web Attack Brute Force", 
                "Web Attack XSS", 
                "Web Attack SQL Injection", 
                "FTP-Patator", 
                "SSH-Patator", 
                "DoS slowloris", 
                "DoS Slowhttptest", 
                "DoS Hulk", 
                "DoS GoldenEye", 
                "Heartbleed"
            ],
            "ì„¤ëª…": [
                "ì •ìƒ íŠ¸ë˜í”½.", 
                "ë¶„ì‚° ì„œë¹„ìŠ¤ ê±°ë¶€(Distributed Denial of Service) ê³µê²©.", 
                "ë„¤íŠ¸ì›Œí¬ í¬íŠ¸ ìŠ¤ìº” ê³µê²©.", 
                "ì•…ì„± ë´‡ í™œë™.", 
                "ë„¤íŠ¸ì›Œí¬ ì¹¨íˆ¬ ë° ê¶Œí•œ íƒˆì·¨.", 
                "ë¬´ì°¨ë³„ ëŒ€ì… ê³µê²©.", 
                "í¬ë¡œìŠ¤ ì‚¬ì´íŠ¸ ìŠ¤í¬ë¦½íŒ….", 
                "SQL ë¬¸ë²•ì„ ì´ìš©í•œ ê³µê²©.", 
                "FTP ì„œë²„ ëŒ€ìƒ ë¬´ì°¨ë³„ ëŒ€ì… ê³µê²©.", 
                "SSH ì„œë²„ ëŒ€ìƒ ë¬´ì°¨ë³„ ëŒ€ì… ê³µê²©.", 
                "HTTP ì—°ê²° ì ìœ ë¡œ ì„œë¹„ìŠ¤ ì¥ì•  ìœ ë°œ.", 
                "HTTP í—¤ë” ê¸°ë°˜ DoS ê³µê²©.", 
                "ì„œë²„ ë¶€í•˜ ì´ˆë˜ DoS ê³µê²©.", 
                "HTTP GET ìš”ì²­ ë‚¨ë°œë¡œ ì„œë²„ ë§ˆë¹„.", 
                "OpenSSL ì·¨ì•½ì  ì•…ìš© ê³µê²©."
            ]
        }

        # DataFrames ìƒì„±
        attacks_df = pd.DataFrame(attacks_data)
        columns_df = pd.DataFrame(columns_data)
        target_labels_df = pd.DataFrame(target_labels_data)

        # ì¶œë ¥
        st.markdown("<h5>ëŒ€í‘œ ê³µê²©</h5>", unsafe_allow_html=True)
        st.dataframe(attacks_df)
        st.markdown("<h5>ì£¼ìš” ì»¬ëŸ¼</h5>", unsafe_allow_html=True)
        st.dataframe(columns_df)
        st.caption("""### ğŸ’¡ì•Œê³  ê°€ë©´ ì¢‹ì€ ì •ë³´ 3ê°€ì§€ ###
        1. íŒ¨í‚·(Packet): ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ì „ì†¡ë˜ëŠ” ë°ì´í„°ì˜ ë‹¨ìœ„ì…ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ íŒ¨í‚·ì€ ë³´í†µ í—¤ë”(ì†¡ìˆ˜ì‹ ì ì •ë³´, í”„ë¡œí† ì½œ ë“±ì˜ ë©”íƒ€ ë°ì´í„° í¬í•¨)ì™€ í˜ì´ë¡œë“œ(ì‹¤ì œ ì „ì†¡í•  ë°ì´í„°)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    2. IAT (Inter-Arrival Time): ì—°ì†ì ì¸ íŒ¨í‚·ë“¤ ì‚¬ì´ì˜ ë„ì°© ì‹œê°„ ê°„ê²©ì…ë‹ˆë‹¤. IATëŠ” ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ì˜ íŒ¨í„´ì„ ë¶„ì„í•  ë•Œ ì‚¬ìš©ë˜ë©°, ì˜ˆë¥¼ ë“¤ì–´ DDoS ê³µê²©ê³¼ ê°™ì€ ë¹„ì •ìƒì ì¸ íŠ¸ë˜í”½ í”Œë¡œìš°ë¥¼ ê°ì§€í•˜ëŠ”ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
    3. ê¸¸ì´(Length): íŒ¨í‚·ì˜ í¬ê¸°ë¥¼ ì˜ë¯¸í•˜ë©°, ë³´í†µ ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ ì¸¡ì •ë©ë‹ˆë‹¤. íŒ¨í‚·ì˜ ê¸¸ì´ëŠ” ë„¤íŠ¸ì›Œí¬ì˜ ë¶€í•˜, ì „ì†¡ ì†ë„, ê·¸ë¦¬ê³  ì‚¬ìš©ëœ í”„ë¡œí† ì½œì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.""")
        st.markdown("<h5>íƒ€ê²Ÿ ë ˆì´ë¸”</h5>", unsafe_allow_html=True)
        st.dataframe(target_labels_df)

    # ì „ì²´ ì›Œí¬í”Œë¡œ ë‹¤ì´ì–´ê·¸ë¨ íƒ­
    with tabs[2]:
        st.markdown("<h4>ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤</h4>", unsafe_allow_html=True)
        local, cloud = image_files[1]
        st.image(get_file_path(local, cloud), use_container_width=True)


# ë°ì´í„° ë¶„ì„ ë° íƒìƒ‰
with pages[1]:
    
    st.markdown("<h4>ë°ì´í„° ë¶„ì„ ë° íƒìƒ‰</h4>", unsafe_allow_html=True)
    
    # ì„œë¸Œíƒ­ ì„¤ì •
    analysis_tabs = st.tabs(["ë°ì´í„° ë¶„í¬ ë° ë³€ìˆ˜ë³„ ìš”ì•½ í†µê³„", "ë°ì´í„° íƒìƒ‰", "ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¤€ë¹„"])

    # ë°ì´í„° ë¶„í¬ íƒ­
    with analysis_tabs[0]:
        analysis_radio = st.radio("ë°ì´í„° ë¶„ì„ ì˜µì…˜ ì„ íƒ", [
            "í¬íŠ¸ ë° íŠ¸ë˜í”½ëŸ‰ ê´€ë ¨", "íŒ¨í‚· ê¸¸ì´ ê´€ë ¨", "í”Œë˜ê·¸ ë° í—¤ë” ê´€ë ¨",
            "ì†ë„ ë° ë¹„ìœ¨ ê´€ë ¨", "ì„¸ê·¸ë¨¼íŠ¸ ë° í•˜ìœ„ í”Œë¡œìš° ê´€ë ¨",
            "ì‹œê°„ ê´€ë ¨", "ìœˆë„ìš° í¬ê¸° ë° ê¸°íƒ€", "í™œë™ ë° íœ´ë©´ ì‹œê°„ ê´€ë ¨", "ë ˆì´ë¸”"
        ])

        columns_dict = {
            "í¬íŠ¸ ë° íŠ¸ë˜í”½ëŸ‰ ê´€ë ¨": [
                "Flow Duration",  # ì£¼ìš” ì¹¼ëŸ¼
                "Total Fwd Packets",  # ì£¼ìš” ì¹¼ëŸ¼
                "Total Backward Packets",  # ì£¼ìš” ì¹¼ëŸ¼
                "Flow Bytes/s",  # ì£¼ìš” ì¹¼ëŸ¼
                "Flow Packets/s",  # ì£¼ìš” ì¹¼ëŸ¼
                "Destination Port"],
            "íŒ¨í‚· ê¸¸ì´ ê´€ë ¨": [
                "Fwd Packet Length Max",  # ì£¼ìš” ì¹¼ëŸ¼
                "Fwd Packet Length Mean",  # ì£¼ìš” ì¹¼ëŸ¼
                "Bwd Packet Length Max",  # ì£¼ìš” ì¹¼ëŸ¼
                "Bwd Packet Length Mean",  # ì£¼ìš” ì¹¼ëŸ¼
                "Total Length of Fwd Packets",
                "Total Length of Bwd Packets",
                "Fwd Packet Length Min",
                "Fwd Packet Length Std",
                "Bwd Packet Length Min",
                "Bwd Packet Length Std",
                "Min Packet Length",
                "Max Packet Length",
                "Packet Length Mean",
                "Packet Length Std",
                "Packet Length Variance"],
            "í”Œë˜ê·¸ ë° í—¤ë” ê´€ë ¨": [
                "PSH Flag Count",  # ì£¼ìš” ì¹¼ëŸ¼
                "URG Flag Count",  # ì£¼ìš” ì¹¼ëŸ¼
                "SYN Flag Count",  # ì£¼ìš” ì¹¼ëŸ¼
                "FIN Flag Count",  # ì£¼ìš” ì¹¼ëŸ¼
                "RST Flag Count",  # ì£¼ìš” ì¹¼ëŸ¼
                "Fwd PSH Flags",
                "Bwd PSH Flags",
                "Fwd URG Flags",
                "Bwd URG Flags",
                "Fwd Header Length",
                "Bwd Header Length",
                "Fwd Header Length.1",
                "ACK Flag Count",
                "CWE Flag Count",
                "ECE Flag Count"],
            "ì†ë„ ë° ë¹„ìœ¨ ê´€ë ¨": [
                "Flow Bytes/s",  
                "Flow Packets/s",  
                "Down/Up Ratio",
                "Average Packet Size",
                "Fwd Avg Bytes/Bulk",
                "Fwd Avg Packets/Bulk",
                "Fwd Avg Bulk Rate",
                "Bwd Avg Bytes/Bulk",
                "Bwd Avg Packets/Bulk",
                "Bwd Avg Bulk Rate"],
            "ì„¸ê·¸ë¨¼íŠ¸ ë° í•˜ìœ„ í”Œë¡œìš° ê´€ë ¨": [
                "Avg Fwd Segment Size",
                "Avg Bwd Segment Size",
                "Subflow Fwd Packets",
                "Subflow Fwd Bytes",
                "Subflow Bwd Packets",
                "Subflow Bwd Bytes"],
            "ì‹œê°„ ê´€ë ¨": [
                "Flow IAT Mean",  # ì£¼ìš” ì¹¼ëŸ¼
                "Flow IAT Std",  # ì£¼ìš” ì¹¼ëŸ¼
                "Flow IAT Max",
                "Flow IAT Min",
                "Fwd IAT Total",
                "Fwd IAT Mean",
                "Fwd IAT Std",
                "Fwd IAT Max",
                "Fwd IAT Min",
                "Bwd IAT Total",
                "Bwd IAT Mean",
                "Bwd IAT Std",
                "Bwd IAT Max",
                "Bwd IAT Min"],
            "ìœˆë„ìš° í¬ê¸° ë° ê¸°íƒ€": [
                "Init_Win_bytes_forward",
                "Init_Win_bytes_backward",
                "act_data_pkt_fwd",
                "min_seg_size_forward"],
            "í™œë™ ë° íœ´ë©´ ì‹œê°„ ê´€ë ¨": [
                "Active Mean",
                "Active Std",
                "Active Max",
                "Active Min",
                "Idle Mean",
                "Idle Std",
                "Idle Max",
                "Idle Min"],
            "ë ˆì´ë¸”": [
                "Label"]  # ì£¼ìš” ì¹¼ëŸ¼
            }
        
        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì— ë”°ë¥¸ ì¹¼ëŸ¼ ë¦¬ìŠ¤íŠ¸
        if analysis_radio in columns_dict:
            selected_columns = columns_dict[analysis_radio]
            
            # ì„ íƒëœ ì¹¼ëŸ¼ì— ëŒ€í•´ íˆìŠ¤í† ê·¸ë¨ê³¼ ë°•ìŠ¤í”Œë¡¯ì„ ê°€ë¡œë¡œ ë°°ì¹˜
            for column in selected_columns:
                st.subheader(f"{column} ë¶„ì„")

                # ê°€ë¡œë¡œ ë‘ ê°œì˜ ì˜ì—­ ë°°ì¹˜
                col1, col2 = st.columns(2)
                
                safe_column_name = re.sub(r'[<>:"/\\|?*]', '_', column) 

                if column == 'Label':
                    # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
                    local, cloud = image_files[2]
                    col1_image = get_file_path(os.path.join(local, f"{analysis_radio}_{safe_column_name}_pie_chart.png"),
                                                os.path.join(cloud, f"{analysis_radio}_{safe_column_name}_pie_chart.png"))
                    col2_image = get_file_path(os.path.join(local, f"{analysis_radio}_{safe_column_name}_bar_chart.png"),
                                                os.path.join(cloud, f"{analysis_radio}_{safe_column_name}_bar_chart.png"))
                else:
                    # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
                    local, cloud = image_files[2]
                    col1_image = get_file_path(os.path.join(local, f"{analysis_radio}_{safe_column_name}_histogram.png"),
                                                os.path.join(cloud, f"{analysis_radio}_{safe_column_name}_histogram.png"))
                    col2_image = get_file_path(os.path.join(local, f"{analysis_radio}_{safe_column_name}_boxplot.png"),
                                                os.path.join(cloud, f"{analysis_radio}_{safe_column_name}_boxplot.png"))
                
                if os.path.exists(col1_image):
                    with col1:
                        st.image(col1_image)
                else:
                    with col1:
                        st.write(f"'{col1_image}' íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                
                if os.path.exists(col2_image):
                    with col2:
                        st.image(col2_image)
                else:
                    with col2:
                        st.write(f"'{col2_image}' íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


    # ë°ì´í„° íƒìƒ‰ íƒ­
    with analysis_tabs[1]:
        exploration_radio = st.radio("íƒìƒ‰ ì˜µì…˜ ì„ íƒ", ["ìŒìˆ˜ ê°’", "ìƒê´€ê´€ê³„"])

        if exploration_radio == "ìŒìˆ˜ ê°’":
            st.subheader("ìŒìˆ˜ ë°ì´í„° ë¹„ìœ¨")
            local, cloud = image_files[3]
            st.image(get_file_path(local, cloud), use_container_width=True)
            # st.image("../results/figures/negative_data_ratio.png")

            st.subheader("ìŒìˆ˜ ê°’ ìƒìœ„ 2ê°œ ì¹¼ëŸ¼")
            local, cloud = image_files[4]
            st.image(get_file_path(local, cloud), use_container_width=True)
            # st.image("../results/figures/negative_columns_top2.png")

            st.subheader("ìŒìˆ˜ ê°’ ì¹¼ëŸ¼2")
            local, cloud = image_files[5]
            st.image(get_file_path(local, cloud), use_container_width=True)
            # st.image("../results/figures/negative_columns_rest.png")

        elif exploration_radio == "ìƒê´€ê´€ê³„":
            st.subheader("ìƒê´€ê³„ìˆ˜ ì ˆëŒ€ê°’ ê¸°ì¤€ ìƒìœ„ 30ê°œ")
            local, cloud = image_files[6]
            st.image(get_file_path(local, cloud), use_container_width=True)
            # st.image("../results/figures/corr.png")

            st.subheader("ìƒê´€ê³„ìˆ˜ 0.9ì´ìƒ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„")
            local, cloud = image_files[7]
            st.image(get_file_path(local, cloud), use_container_width=True)
            # st.image("../results/figures/corr_network.png")

    # ë°ì´í„° ì „ì²˜ë¦¬ íƒ­
    with analysis_tabs[2]:
        preprocessing_radio = st.radio("ì „ì²˜ë¦¬ ì˜µì…˜ ì„ íƒ", ["ì œê±°ëœ ì¹¼ëŸ¼", "ì œê±°ëœ ë°ì´í„°"])
        if preprocessing_radio == "ì œê±°ëœ ì¹¼ëŸ¼":
            st.subheader("ì œê±°ëœ ì¹¼ëŸ¼")
            local, cloud = image_files[8]
            st.image(get_file_path(local, cloud), use_container_width=True)
            # st.image("../results/figures/col_drop.png")
            st.markdown("#### ë‹¨ í•˜ë‚˜ì˜ ê°’ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ì¹¼ëŸ¼ ì œê±°")
            st.code(body="""
                    # ë‹¨ í•˜ë‚˜ì˜ ê°’ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ì¹¼ëŸ¼ ì°¾ê¸°
                    single_value_columns = [col for col in df.columns if df[col].nunique() == 1]
                    df_cleaned = df.drop(columns=single_value_columns)
                    """, language="python")
            
            single_value_colums = ['Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']
            df_single_value_colums = pd.DataFrame(single_value_colums, columns=["ì œê±°ëœ ì¹¼ëŸ¼"])
            st.write(df_single_value_colums)

            st.markdown("#### ë™ì¼í•œ ì¹¼ëŸ¼ ì œê±°")
            st.code(body="""
                    # ê° ì¹¼ëŸ¼ì˜ ê°’ì„ tupleë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
                    grouped_columns = {}

                    for col in df_cleaned.columns:
                        col_values = tuple(df_cleaned[col].values)  # ê° ì¹¼ëŸ¼ì˜ ê°’ì„ tupleë¡œ ë³€í™˜
                        if col_values in grouped_columns:  # ë™ì¼í•œ ê°’ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            grouped_columns[col_values].append(col)  # ê·¸ë£¹ì— ì¶”ê°€
                        else:
                            grouped_columns[col_values] = [col]  # ìƒˆë¡œìš´ ê·¸ë£¹ ìƒì„±

                    # ê·¸ë£¹í™”ëœ ì¹¼ëŸ¼ ì¤‘ 2ê°œ ì´ìƒ í¬í•¨ëœ ê²ƒë§Œ ì¶”ì¶œ
                    grouped_result = [group for group in grouped_columns.values() if len(group) > 1]
                    """, language="python")
            
            grouped_columns = [
                ['Total Fwd Packets', 'Subflow Fwd Packets'],
                ['Total Backward Packets', 'Subflow Bwd Packets'],
                ['Fwd Packet Length Mean', 'Avg Fwd Segment Size'],
                ['Bwd Packet Length Mean', 'Avg Bwd Segment Size'],
                ['Fwd PSH Flags', 'SYN Flag Count'],
                ['Fwd URG Flags', 'CWE Flag Count'],
                ['Fwd Header Length', 'Fwd Header Length.1']
            ]

            # DataFrame ìƒì„±
            df_grouped_columns = pd.DataFrame(grouped_columns, columns=["ì¹¼ëŸ¼1", "ì œê±°ëœ ì¹¼ëŸ¼1ê³¼ ë™ì¼í•œ ì¹¼ëŸ¼"])
            st.write(df_grouped_columns)

        elif preprocessing_radio == "ì œê±°ëœ ë°ì´í„°":
            st.subheader("ì œê±°ëœ ë°ì´í„°")
            st.markdown("#### ìŒìˆ˜ê°€ í¬í•¨ëœ ì¹¼ëŸ¼ì˜ ìŒìˆ˜ ë°ì´í„°ì˜ Label ì¹¼ëŸ¼ unique ê°’ì´ 0 í•˜ë‚˜ì¸ ë°ì´í„° ì‚­ì œ")
            st.code("""
                    # ìŒìˆ˜ê°€ í¬í•¨ëœ ì¹¼ëŸ¼ë“¤ ì¶”ì¶œ
                    negative_columns = df.columns[df.min() < 0]

                    # 'Label' ì¹¼ëŸ¼ì˜ unique ê°’ì´ 0 í•˜ë‚˜ì¸ ìŒìˆ˜ê°€ í¬í•¨ëœ ì¹¼ëŸ¼ ì¶”ì¶œ
                    negative_columns_with_only_zero_label = [
                    col for col in negative_columns
                    if df[df[col] < 0]['Label'].nunique() == 1 
                    and df[df[col] < 0]['Label'].unique()[0] == 0]
                    """, language="python")
            
            negative_columns_with_only_zero_label = ['Flow Duration', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Max', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Header Length.1', 'min_seg_size_forward']
            df_negative_columns_with_only_zero_label = pd.DataFrame(negative_columns_with_only_zero_label, columns=["í•´ë‹¹ ì¹¼ëŸ¼ì˜ ìŒìˆ˜ ë°ì´í„° ì‚­ì œ"])

            st.write(df_negative_columns_with_only_zero_label)
            st.text("ì œê±°ëœ ë°ì´í„° ìˆ˜: 150 ê°œ")

# ëª¨ë¸
with pages[2]:
    st.markdown("<h4>ëª¨ë¸</h4>", unsafe_allow_html=True)

    # ì„œë¸Œíƒ­ ì„¤ì •
    model_tabs = st.tabs(["ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ", "ìµœì¢… ëª¨ë¸"])

    # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ íƒ­
    with model_tabs[0]:
        local, cloud = image_files[9]
        df_models_scores = pd.read_csv(get_file_path(local, cloud), converters={
            'Scaler': str,  # 'Scaler' ì»¬ëŸ¼ì€ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
            'PCA': str       # 'PCA' ì»¬ëŸ¼ë„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
        })
        
        # ëª¨ë¸ íƒ€ì… ì„ íƒ (ì´ì§„/ë‹¤ì¤‘ ë¶„ë¥˜)
        model_type = st.radio("ëª¨ë¸ íƒ€ì… ì„ íƒ", ["Binary", "Multi"])
        
        if model_type == "Multi":
            # ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ì— ëŒ€í•œ ì„¤ì •
            st.subheader("ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ í•„í„°ë§")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë²„íŠ¼ (None, MinMax, Standard)
            scaler_type = st.radio("ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ", ['None', 'MinMaxScaler()', 'StandardScaler()'], index=0)

            # PCA ë²„íŠ¼ (None, ë¶„ì‚° 0.99, ì£¼ì„±ë¶„ 10)
            pca_type = st.radio("PCA ì„ íƒ", ['None', '0.99', '10'], index=0)
            
            # ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ í•„í„°ë§ (Typeì´ Multiì¸ ëª¨ë¸ë§Œ)
            multi_models = df_models_scores[df_models_scores['Type'] == "multiclass"]

            # ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ì„ ë‹¤ì¤‘ ì„ íƒí•  ìˆ˜ ìˆê²Œ í•˜ê¸°
            selected_models = st.multiselect("ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ ì„ íƒ", multi_models['Model'].unique(), default=multi_models['Model'].unique())
            
            # ì„ íƒëœ ëª¨ë¸ì— ë§ê²Œ í•„í„°ë§
            filtered_data = df_models_scores[
                (df_models_scores['Type'] == "multiclass") &
                (df_models_scores['Scaler'] == str(scaler_type)) &
                (df_models_scores['PCA'] == str(pca_type)) &
                (df_models_scores['Model'].isin(selected_models))
            ]
            
            # ì„±ëŠ¥ ì§€í‘œ 4ê°œ (Accuracy, F1 Score, MSE, R2)ë¥¼ êº¾ì€ì„  ê·¸ë˜í”„ë¡œ ì‹œê°í™”
            if not filtered_data.empty:
                st.subheader(f"ì„±ëŠ¥ ì§€í‘œ (ëª¨ë¸: {', '.join(selected_models)})")
                metrics = ['Accuracy', 'F1 Score', 'R2', 'MSE']
                
                plt.figure(figsize=(12, 6))
                
                # ê° ëª¨ë¸ì— ëŒ€í•´ ì„±ëŠ¥ ì§€í‘œë¥¼ êº¾ì€ì„  ê·¸ë˜í”„ë¡œ ê·¸ë¦¬ê¸°
                for model in selected_models:
                    model_data = filtered_data[filtered_data['Model'] == model]
                    sns.lineplot(x='Metric', y='Value', data=model_data.melt(id_vars=["Model"], value_vars=metrics, var_name="Metric", value_name="Value"), label=model)
                
                plt.title(f"ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ìŠ¤ì¼€ì¼ëŸ¬: {scaler_type}, PCA: {pca_type})")
                plt.xlabel('ì„±ëŠ¥ ì§€í‘œ')
                plt.ylabel('ì„±ëŠ¥ ê°’')
                plt.legend(title='ëª¨ë¸', bbox_to_anchor=(1.05, 1), loc='upper left')
                st.pyplot(plt)

            else:
                st.write("ì„ íƒí•œ ì¡°ê±´ì— ë§ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        elif model_type == "Binary":
            # ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì— ëŒ€í•œ ì„¤ì •
            st.subheader("ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ í•„í„°ë§")
            
            # ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ í•„í„°ë§ (Typeì´ Binaryì¸ ëª¨ë¸ë§Œ)
            binary_models = df_models_scores[df_models_scores['Type'] == "binary"]

            # ì„ íƒëœ ëª¨ë¸ì— ë§ê²Œ í•„í„°ë§
            filtered_data = df_models_scores[
                (df_models_scores['Type'] == "binary") &
                (df_models_scores['Scaler'] == "StandardScaler()") &
                (df_models_scores['PCA'] == str(None))
            ]
            
            # ì„±ëŠ¥ ì§€í‘œ 4ê°œ (Accuracy, F1 Score, MSE, R2)ë¥¼ êº¾ì€ì„  ê·¸ë˜í”„ë¡œ ì‹œê°í™”
            if not filtered_data.empty:
                st.markdown('#### ìŠ¤ì¼€ì¼ëŸ¬: StandardScaler(), PCA: None)')
                
                # ë°ì´í„° ë³€í˜• (meltë¡œ ì„±ëŠ¥ ì§€í‘œë¥¼ ê¸¸ê²Œ ë³€í™˜)
                filtered_data_melted = filtered_data.melt(id_vars=["Model"], value_vars=['Accuracy', 'F1 Score', 'R2', 'MSE'],
                                                          var_name="Metric", value_name="Value")
                
                # ì„±ëŠ¥ ì§€í‘œë¥¼ êº¾ì€ì„  ê·¸ë˜í”„ë¡œ ê·¸ë¦¬ê¸°
                plt.figure(figsize=(12, 6))
                sns.lineplot(x="Metric", y="Value", hue="Model", data=filtered_data_melted, marker='o')
                
                plt.title(f"ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
                plt.xlabel('ì„±ëŠ¥ ì§€í‘œ')
                plt.ylabel('ê°’')
                plt.legend(title='ëª¨ë¸', bbox_to_anchor=(1.05, 1), loc='upper left')
                st.pyplot(plt)
            
    # ìµœì¢… ëª¨ë¸ íƒ­
    with model_tabs[1]:
        st.subheader("ìµœì¢… ëª¨ë¸ ì„±ëŠ¥")
        # ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ì„ ì°¾ê¸°
        best_model = df_models_scores[(df_models_scores['Model'] == 'xgb') & 
                                    (df_models_scores['Scaler'] == 'None') & 
                                    (df_models_scores['PCA'] == 'None')]

        # ì„±ëŠ¥ ì§€í‘œ
        accuracy = best_model['Accuracy'].values[0]
        f1_score = best_model['F1 Score'].values[0]
        mse = best_model['MSE'].values[0]
        r2 = best_model['R2'].values[0]

        # ì„±ëŠ¥ ì§€í‘œë¥¼ ì‹œê°í™”
        fig, ax = plt.subplots()
        metrics = ['Accuracy', 'F1 Score', 'R2', 'MSE']
        values = [accuracy, f1_score, r2, mse]

        ax.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])
        ax.set_ylabel('Score')
        ax.set_title('Model Performance Metrics')
        st.pyplot(fig)

        # classification_report íŒŒì¼ ê²½ë¡œ
        local, cloud = image_files[10]
        report_path = get_file_path(local, cloud)
        

        # classification_report ì½ê¸°
        with open(report_path, "r") as f:
            report_content = f.read()

        # classification_reportë¥¼ Streamlitì— í‘œì‹œ
        st.subheader("Classification Report")
        st.text(report_content)

# ë³´ê³ ì„œ
with pages[3]:
    st.markdown("<h4>ë³´ê³ ì„œ</h4>", unsafe_allow_html=True)

    # ì„œë¸Œíƒ­ ì„¤ì •
    report_tabs = st.tabs(["ë…¼ì˜ì  ë° ë¯¸ë˜ ì‘ì—…"])

    # ì²« ë²ˆì§¸ ì„œë¸Œíƒ­ ë‚´ìš©
    with report_tabs[0]:
        st.subheader("ì¶”í›„ ë…¼ì˜ì ")
        st.markdown("""
        - **ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ í‘œë³¸ ë¶€ì¡±**: íŠ¹ì • ì†Œìˆ˜ í´ë˜ìŠ¤(10ê°œ ì´í•˜ì˜ ë°ì´í„°)ì˜ ê²½ìš°, í‘œë³¸ ìˆ˜ê°€ ë„ˆë¬´ ì ì–´ íŒ¨í„´ ë¶„ì„ì— ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤.
        - **ë°ì´í„° í¸ì°¨ë¡œ ì¸í•œ ëª¨ë¸ í¸í–¥**: ë°ì´í„°ì˜ í¸ì°¨ë¡œ ì¸í•´ DDoS ìª½ì— ëª¨ë¸ì´ í¸í–¥ë˜ì–´ Web Attack ë° SQL Attackê³¼ ê°™ì€ ê³µê²©ì— ìƒëŒ€ì ìœ¼ë¡œ ì•½í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
        - **ê³µê²© ìœ í˜•ë³„ í”¼í•´ ì •ë„**: DDoS ê³µê²©ë³´ë‹¤ Web Attackì´ë‚˜ Database ê´€ë ¨ ê³µê²©ì´ ë” í° í”¼í•´ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì ì€ í‘œë³¸ì´ë”ë¼ë„ ì´ëŸ¬í•œ ê³µê²© ìœ í˜•ì— ëŒ€í•œ ë¶„ì„ì„ ê°•í™”í•´ì•¼ í•©ë‹ˆë‹¤.
        - **ì‹œê³„ì—´ ë°ì´í„° ì¶”ê°€**: ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬, ëª¨ë¸ì˜ ì„±ëŠ¥ ë° ì´ìƒ íƒì§€ ëŠ¥ë ¥ì„ ê°œì„ í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.
        """)

        st.subheader("íšŒê³  ë° ê°œì„ ì ")
        st.markdown("""
        - **ì•„ì‰¬ì› ë˜ ì **: 2017ë…„ê³¼ 2018ë…„ì˜ ë°ì´í„°ì…‹ì´ ì œê³µë˜ì—ˆì§€ë§Œ, ì¹¼ëŸ¼ êµ¬ì¡°ì˜ ì°¨ì´ë¡œ ì¸í•´ 2018ë…„ ë°ì´í„°ë¥¼ ê²€ì¦ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.
        - **ë°°ìš´ ì **: íŒ€ì›ë“¤ê³¼ í•¨ê»˜ ì‘ì—…í•˜ë©´ì„œ ë§ì€ ê²ƒì„ ë°°ì› ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë™ì¼í•œ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ìˆ˜ì¹˜ ì°¨ì´ê°€ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ ë°œê²¬í•˜ê³  í•´ê²°í•˜ë©´ì„œ ë°ì´í„°ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
        - **í˜‘ì—…ì˜ ì¤‘ìš”ì„±**: Gitì„ í™œìš©í•œ í˜‘ì—…ì„ í†µí•´ íŒ€ì› ê°„ ì†Œí†µê³¼ ë°°ë ¤ì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤. ì„œë¡œì˜ ì‘ì—… ë‚´ìš©ì„ ê³µìœ í•˜ë©° í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.""")